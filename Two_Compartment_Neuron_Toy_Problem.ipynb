{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Two-Compartment Spiking Neuron on a Temporal Coincidence Task\n",
        "\n",
        "This notebook explores whether a **two-compartment leaky integrate-and-fire (LIF) neuron**\n",
        "(basal + apical) can better detect temporal relationships between inputs than a standard\n",
        "one-compartment SNN.\n",
        "\n",
        "We will:\n",
        "- Generate a synthetic **temporal coincidence dataset** where the label depends on\n",
        "  whether an apical spike *predicts* a later basal spike.\n",
        "- Train:\n",
        "  - A **two-compartment SNN** (basal + apical compartments, then soma)\n",
        "  - A **one-compartment SNN** (all input merged into one)\n",
        "- Compare:\n",
        "  - Accuracy over seeds\n",
        "  - Training curves\n",
        "  - **Ablation tests**: what happens if we remove basal or apical input at test time?\n",
        "- Discuss what this tells us about timing and compartmentalization.\n"
      ],
      "metadata": {
        "id": "La_aiv6olF9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "T = 30     # sequence length\n",
        "t_apical = 10\n",
        "delay = 3\n",
        "t_basal = t_apical + delay\n",
        "\n",
        "num_classes = 2\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "lr = 1e-3\n"
      ],
      "metadata": {
        "id": "RgqmcNdMho9P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to ensure reproducibility\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n"
      ],
      "metadata": {
        "id": "pQOhjUjmx_KN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using snnTorch as\n",
        "\n",
        "!pip install snntorch\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "\n",
        "spike_grad = surrogate.fast_sigmoid()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcHqr86XiMZ0",
        "outputId": "b1ff7d0e-2576-4e65-a27e-18aaa042f960"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temporal coincidence dataset (`BasalApicalDataset`)\n",
        "\n",
        "I created a simple two-input temporal pattern classification task.\n",
        "\n",
        "Each sample consists of:\n",
        "\n",
        "- An input tensor `x` of shape `[T, 2]` (time × channel)\n",
        "- A label `y` in `{0, 1}`\n",
        "\n",
        "Channel meanings:\n",
        "\n",
        "- Channel 0: **apical** input  \n",
        "- Channel 1: **basal** input  \n",
        "\n",
        "The label depends on whether the **apical spike correctly predicts the basal spike** in time.\n",
        "\n",
        "### Class definitions\n",
        "\n",
        "- **Class 1 (`y = 1`): coincidence / correct prediction**\n",
        "  - Apical spikes around a nominal time `t_apical` (with small jitter).\n",
        "  - Basal spikes a fixed `delay` time steps after the apical spike.\n",
        "  - So basal reliably follows apical with the correct timing.\n",
        "\n",
        "- **Class 0 (`y = 0`): non-coincidence**\n",
        "  - Basal still spikes at the “expected” basal time `t_basal = t_apical + delay`.\n",
        "  - Apical either:\n",
        "    - does **not** spike at all, or  \n",
        "    - spikes at a clearly **wrong** time (for example, much earlier or much later),\n",
        "      so it does not predict basal.\n",
        "\n",
        "In other words:\n",
        "\n",
        "> The task is: did the apical input correctly predict the basal spike with the right delay?\n",
        "\n",
        "### Concrete examples (showing only non-zero time steps)\n",
        "\n",
        "Assume:\n",
        "\n",
        "- `T = 30`\n",
        "- `t_apical = 10`\n",
        "- `delay = 3` → `t_basal = 13`\n",
        "\n",
        "**Example of class 1 (`y = 1` — correct temporal prediction):**\n",
        "\n",
        "Apical fires slightly before basal with the correct delay:\n",
        "\n",
        "time | basal | apical  \n",
        "---- | ----- | ------  \n",
        "11   | 0     | 1  \n",
        "14   | 1     | 0  \n",
        "\n",
        "**Example of class 0 (`y = 0` — no valid prediction):**\n",
        "\n",
        "Basal fires at the expected time, but there is no predictive apical spike:\n",
        "\n",
        "time | basal | apical  \n",
        "---- | ----- | ------  \n",
        "13   | 1     | 0  \n"
      ],
      "metadata": {
        "id": "mZTx78QB5JNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasalApicalDataset(Dataset):\n",
        "    def __init__(self, n_samples=10000, T=30, t_apical=10, delay=3,\n",
        "                 p_class1=0.5, device=\"cpu\"):\n",
        "        self.n_samples = n_samples\n",
        "        self.T = T\n",
        "        self.t_apical = t_apical\n",
        "        self.delay = delay\n",
        "        self.t_basal = t_apical + delay\n",
        "        self.p_class1 = p_class1\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.zeros(self.T, 2, device=self.device)  # [T, 2]\n",
        "        # randomly pick class\n",
        "        y = 1 if random.random() < self.p_class1 else 0\n",
        "        if y == 1:\n",
        "            # apical precedes basal with jitter\n",
        "            jitter = random.choice([-1, 0, 1])\n",
        "            t_a = min(max(self.t_apical + jitter, 0), self.T-1)\n",
        "            t_b = min(t_a + self.delay, self.T-1)\n",
        "\n",
        "            x[t_a, 1] = 1.0\n",
        "            x[t_b, 0] = 1.0\n",
        "        else:\n",
        "            # basal only, or apical at wrong temporal relationship\n",
        "            x[self.t_basal, 0] = 1.0\n",
        "            # maybe wrong-time apical\n",
        "            if random.random() < 0.5:\n",
        "                wrong_t = self.t_apical + random.choice([-5, 5])\n",
        "                if 0 <= wrong_t < self.T:\n",
        "                    x[wrong_t, 1] = 1.0\n",
        "\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "j2knRZGqoYnq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-compartment SNN baseline (`SingleCompartmentSNN`)\n",
        "\n",
        "This class defines a simple **one-compartment spiking neural network** that to use as a baseline.\n",
        "\n",
        "Key points:\n",
        "\n",
        "- **Input shape:** the network expects input of shape `[T, B, 2]`  \n",
        "  - `T` = number of time steps  \n",
        "  - `B` = batch size  \n",
        "  - `2` = two input channels (apical and basal merged into a single stream for this model)\n",
        "\n",
        "- **Linear input layer (`fc`):**  \n",
        "  A fully connected layer maps the 2 input channels into a hidden layer of size `hidden_size`.  \n",
        "  This produces a current for each hidden neuron at each time step.\n",
        "\n",
        "- **LIF neuron layer (`self.lif` from snnTorch):**  \n",
        "  - Integrates input over time with leakage (`beta=0.9`).  \n",
        "  - Emits a spike when the membrane voltage crosses a threshold (`threshold=1.0`).  \n",
        "  - Uses a surrogate gradient (`spike_grad`) so we can train with backpropagation.\n",
        "\n",
        "- **Temporal processing:**  \n",
        "  For each time step `t`:\n",
        "  1. Take the input at time `t`.\n",
        "  2. Pass it through the linear layer to get input current.\n",
        "  3. Update the LIF neuron state and record whether each neuron spikes.\n",
        "\n",
        "- **Spike readout:**  \n",
        "  After all `T` time steps:\n",
        "  - We sum spikes over time for each hidden neuron (`spike_counts`).\n",
        "  - These spike counts go into a final linear layer (`readout`) to produce class logits.\n",
        "\n",
        "This gives us a standard one-compartment spiking network to compare against the two-compartment model on the same temporal coincidence task.\n"
      ],
      "metadata": {
        "id": "Zb00Alqi8FpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleCompartmentSNN(nn.Module):\n",
        "    def __init__(self, hidden_size=16, num_classes=2):\n",
        "        super().__init__()\n",
        "        # one weight matrix from 2 input channels -> hidden neurons\n",
        "        self.fc = nn.Linear(2, hidden_size, bias=False)\n",
        "\n",
        "        # snnTorch leaky neuron (single compartment)\n",
        "        self.lif = snn.Leaky(\n",
        "            beta=0.9,\n",
        "            threshold=1.0,\n",
        "            learn_beta=False,\n",
        "            spike_grad=spike_grad\n",
        "        )\n",
        "\n",
        "        self.readout = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [T, B, 2]\n",
        "        \"\"\"\n",
        "        T, B, _ = x.shape\n",
        "        mem = torch.zeros(B, self.fc.out_features, device=x.device)\n",
        "        spk_seq = []\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x[t]\n",
        "            I = self.fc(x_t)\n",
        "            spk, mem = self.lif(I, mem)\n",
        "            spk_seq.append(spk)\n",
        "\n",
        "        spk_seq = torch.stack(spk_seq, dim=0)\n",
        "        spike_counts = spk_seq.sum(dim=0)\n",
        "        logits = self.readout(spike_counts)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "1lfjIrtZ7zFT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two-compartment spiking neuron (`TwoCompartmentLIF` and `TwoCompartmentSNN`)\n",
        "\n",
        "The goal of this section is to build a spiking neuron that is a bit closer to biology by giving it **two separate compartments**:\n",
        "\n",
        "- a **basal compartment** (for feedforward / sensory input)\n",
        "- an **apical compartment** (for contextual / feedback input)\n",
        "\n",
        "Instead of a single membrane voltage, this neuron keeps track of:\n",
        "\n",
        "- `V_b`: basal voltage (one value per hidden neuron)\n",
        "- `V_a`: apical voltage (one value per hidden neuron)\n",
        "- `V_soma`: combined somatic voltage used to decide if the neuron spikes\n",
        "\n",
        "### Inputs and shape\n",
        "\n",
        "The `forward` method expects input of shape:\n",
        "\n",
        "- `x` of shape `[T, B, 2]`\n",
        "  - `T` = number of time steps\n",
        "  - `B` = batch size\n",
        "  - channel 0 = basal input\n",
        "  - channel 1 = apical input\n",
        "\n",
        "At each time step `t`, split:\n",
        "\n",
        "- `x_basal = x[t, :, 0:1]`  → goes through a linear layer `W_basal`\n",
        "- `x_apical = x[t, :, 1:2]` → goes through a linear layer `W_apical`\n",
        "\n",
        "Each of these layers projects its input into `hidden_size` neurons, so we get:\n",
        "\n",
        "- `I_b`: basal current into each hidden neuron\n",
        "- `I_a`: apical current into each hidden neuron\n",
        "\n",
        "### Leaky integration in each compartment\n",
        "\n",
        "For each hidden neuron, we maintain two voltages that evolve over time:\n",
        "\n",
        "- `V_b` (basal voltage)\n",
        "- `V_a` (apical voltage)\n",
        "\n",
        "On every time step:\n",
        "\n",
        "- `V_b` is updated with a **leaky integrate-and-fire style** rule:\n",
        "  - old voltage is multiplied by a decay term `alpha_b`\n",
        "  - new basal current `I_b` is added\n",
        "- `V_a` is updated similarly with decay `alpha_a` and current `I_a`\n",
        "\n",
        "This means **basal and apical inputs have their own separate time dynamics**:  \n",
        "they can rise and decay differently over time before being combined.\n",
        "\n",
        "### Combining into a somatic voltage\n",
        "\n",
        "To decide whether the neuron spikes, we form a **somatic voltage**:\n",
        "\n",
        "- `V_soma = V_b + apical_gain * V_a`\n",
        "\n",
        "Here:\n",
        "\n",
        "- `V_b` captures what the neuron is getting from its basal (feedforward) inputs.\n",
        "- `V_a` captures what it is getting from apical (contextual) inputs.\n",
        "- `apical_gain` controls how strongly the apical compartment influences the soma.\n",
        "\n",
        "In other words, apical input does not directly change the output spike.  \n",
        "It first builds up its own voltage trace, then modulates the soma through this weighted combination.\n",
        "\n",
        "### Spiking and reset\n",
        "\n",
        "Once we have `V_soma`, we decide whether the neuron spikes:\n",
        "\n",
        "- A **surrogate spike** `s = spike_grad(V_soma - v_th)` is used for training.\n",
        "  - This is a smooth approximation of a step function, so gradients can flow.\n",
        "- A **hard spike** `s_hard = (V_soma >= v_th)` is used for reset logic.\n",
        "  - Wherever `s_hard` is 1, we reset `V_b` and `V_a` back to `v_reset` (typically 0).\n",
        "  - This mimics a real spiking neuron: after a spike, the membrane potential is reset.\n",
        "\n",
        "We record:\n",
        "\n",
        "- `spikes[t]` = surrogate spikes at time `t` for all hidden neurons\n",
        "- `Vs[t]` = somatic voltage at time `t` for all hidden neurons\n",
        "\n",
        "At the end of the sequence, we stack these over time:\n",
        "\n",
        "- `spikes` has shape `[T, B, hidden_size]`\n",
        "- `Vs` has shape `[T, B, hidden_size]`\n",
        "\n",
        "These are returned by `TwoCompartmentLIF`.\n",
        "\n",
        "### Wrapping into a classifier (`TwoCompartmentSNN`)\n",
        "\n",
        "`TwoCompartmentSNN` uses this two-compartment cell as its core:\n",
        "\n",
        "1. Pass the input sequence `x` of shape `[T, B, 2]` through `TwoCompartmentLIF`.\n",
        "2. Sum spikes over time to get a spike count for each hidden neuron:\n",
        "   - `spike_counts = spikes.sum(dim=0)`  → shape `[B, hidden_size]`\n",
        "3. Feed `spike_counts` into a final linear layer `readout` to produce class logits.\n",
        "\n",
        "This gives a **two-compartment SNN classifier** that:\n",
        "\n",
        "- Separately integrates basal and apical inputs over time.\n",
        "- Combines them at the soma when deciding to spike.\n",
        "- Can be trained end-to-end with surrogate gradients, just like the one-compartment baseline.\n"
      ],
      "metadata": {
        "id": "UWQQRNNm6M0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoCompartmentLIF(nn.Module):\n",
        "    def __init__(self, in_basal=1, in_apical=1, hidden_size=16,\n",
        "                 tau_b=20.0, tau_a=20.0,\n",
        "                 v_th=1.0, apical_gain=1.0, v_reset=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.W_basal  = nn.Linear(in_basal, hidden_size, bias=False)\n",
        "        self.W_apical = nn.Linear(in_apical, hidden_size, bias=False)\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau_b = tau_b\n",
        "        self.tau_a = tau_a\n",
        "        self.v_th = v_th\n",
        "        self.v_reset = v_reset\n",
        "        self.apical_gain = apical_gain\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [T, B, 2]\n",
        "        Returns:\n",
        "            spikes: [T, B, hidden_size]  (surrogate spikes for training)\n",
        "            V_soma: [T, B, hidden_size]\n",
        "        \"\"\"\n",
        "        T, B, _ = x.shape\n",
        "\n",
        "        V_b = torch.zeros(B, self.hidden_size, device=x.device)\n",
        "        V_a = torch.zeros(B, self.hidden_size, device=x.device)\n",
        "\n",
        "        spikes = []\n",
        "        Vs = []\n",
        "\n",
        "        alpha_b = math.exp(-1.0 / self.tau_b)\n",
        "        alpha_a = math.exp(-1.0 / self.tau_a)\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x[t]\n",
        "            x_basal  = x_t[:, 0:1]\n",
        "            x_apical = x_t[:, 1:2]\n",
        "\n",
        "            I_b = self.W_basal(x_basal)\n",
        "            I_a = self.W_apical(x_apical)\n",
        "\n",
        "            V_b = alpha_b * V_b + I_b\n",
        "            V_a = alpha_a * V_a + I_a\n",
        "\n",
        "            V_soma = V_b + self.apical_gain * V_a\n",
        "\n",
        "            # surrogate spike: differentiable\n",
        "            s = spike_grad(V_soma - self.v_th)\n",
        "\n",
        "            # hard spike only for reset logic\n",
        "            s_hard = (V_soma >= self.v_th).float()\n",
        "\n",
        "            # reset with hard spikes, but don't kill gradients:\n",
        "            V_b = torch.where(s_hard > 0, torch.full_like(V_b, self.v_reset), V_b)\n",
        "            V_a = torch.where(s_hard > 0, torch.full_like(V_a, self.v_reset), V_a)\n",
        "\n",
        "            spikes.append(s)\n",
        "            Vs.append(V_soma)\n",
        "\n",
        "        spikes = torch.stack(spikes, dim=0)\n",
        "        Vs = torch.stack(Vs, dim=0)\n",
        "        return spikes, Vs\n"
      ],
      "metadata": {
        "id": "ZDEFLL6LksCh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoCompartmentSNN(nn.Module):\n",
        "    def __init__(self, hidden_size=16, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.tc_cell = TwoCompartmentLIF(\n",
        "            in_basal=1, in_apical=1, hidden_size=hidden_size,\n",
        "            tau_b=20.0, tau_a=20.0,\n",
        "            v_th=1.0, apical_gain=1.0\n",
        "        )\n",
        "        self.readout = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spikes, Vs = self.tc_cell(x)\n",
        "        spike_counts = spikes.sum(dim=0)\n",
        "        logits = self.readout(spike_counts)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "x4k1wgDAidme"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standard training loop\n",
        "\n",
        "def train_model(model_cls, num_epochs=10, seed=0):\n",
        "    set_seed(seed)\n",
        "\n",
        "    # new dataset for this seed\n",
        "    train_dataset = BasalApicalDataset(n_samples=8000, T=T, t_apical=t_apical,\n",
        "                                       delay=delay, device=device)\n",
        "    test_dataset  = BasalApicalDataset(n_samples=2000, T=T, t_apical=t_apical,\n",
        "                                       delay=delay, device=device)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_cls().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    test_acc_hist = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct, total_examples = 0.0, 0, 0\n",
        "        for x, y in train_loader:\n",
        "            x = x.transpose(0,1).to(device)  # [T,B,2]\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            preds = logits.argmax(dim=-1)\n",
        "            total_correct += (preds == y).sum().item()\n",
        "            total_examples += y.size(0)\n",
        "        train_acc = total_correct / total_examples\n",
        "\n",
        "        # eval\n",
        "        model.eval()\n",
        "        total_correct, total_examples = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x = x.transpose(0,1).to(device)\n",
        "                y = y.to(device)\n",
        "                logits = model(x)\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                total_correct += (preds == y).sum().item()\n",
        "                total_examples += y.size(0)\n",
        "        test_acc = total_correct / total_examples\n",
        "        test_acc_hist.append(test_acc)\n",
        "\n",
        "    return model, test_acc_hist\n"
      ],
      "metadata": {
        "id": "BhE0-vwdyIkx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define simple wrappers\n",
        "class TCWrapper(nn.Module):\n",
        "    def __init__(self, hidden_size=16, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.model = TwoCompartmentSNN(hidden_size=hidden_size, num_classes=num_classes)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class SCWrapper(nn.Module):\n",
        "    def __init__(self, hidden_size=16, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.model = SingleCompartmentSNN(hidden_size=hidden_size, num_classes=num_classes)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "Seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "tc_final_acc = []\n",
        "sc_final_acc = []\n",
        "\n",
        "for s in Seeds:\n",
        "    _, tc_hist = train_model(TCWrapper, num_epochs=10, seed=s)\n",
        "    _, sc_hist = train_model(SCWrapper, num_epochs=10, seed=s)\n",
        "    tc_final_acc.append(tc_hist[-1])\n",
        "    sc_final_acc.append(sc_hist[-1])\n",
        "\n",
        "print(\"Two-comp final test acc per seed:\", tc_final_acc)\n",
        "print(\"One-comp final test acc per seed:\", sc_final_acc)\n",
        "print(\"Two-comp mean ± std:\", np.mean(tc_final_acc), np.std(tc_final_acc))\n",
        "print(\"One-comp  mean ± std:\", np.mean(sc_final_acc), np.std(sc_final_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5roPuLTySi9",
        "outputId": "f520e2e0-4874-4413-9d1e-3d2bbc8aa945"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two-comp final test acc per seed: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "One-comp final test acc per seed: [0.88, 1.0, 1.0, 0.8845, 1.0]\n",
            "Two-comp mean ± std: 1.0 0.0\n",
            "One-comp  mean ± std: 0.9529 0.05770303284923593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two-comp is slightly more robust, but this is expected given its architecture is very suited for this task"
      ],
      "metadata": {
        "id": "b0FD6WTA9rT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_log(model_cls, num_epochs=20, seed=0):\n",
        "    set_seed(seed)\n",
        "\n",
        "    train_dataset = BasalApicalDataset(n_samples=8000, T=T, t_apical=t_apical,\n",
        "                                       delay=delay, device=device)\n",
        "    test_dataset  = BasalApicalDataset(n_samples=2000, T=T, t_apical=t_apical,\n",
        "                                       delay=delay, device=device)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = model_cls().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_acc_hist, test_acc_hist = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_correct, total_examples = 0, 0\n",
        "        for x, y in train_loader:\n",
        "            x = x.transpose(0,1).to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = logits.argmax(dim=-1)\n",
        "            total_correct += (preds == y).sum().item()\n",
        "            total_examples += y.size(0)\n",
        "\n",
        "        train_acc = total_correct / total_examples\n",
        "\n",
        "        model.eval()\n",
        "        total_correct, total_examples = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x = x.transpose(0,1).to(device)\n",
        "                y = y.to(device)\n",
        "                logits = model(x)\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                total_correct += (preds == y).sum().item()\n",
        "                total_examples += y.size(0)\n",
        "        test_acc = total_correct / total_examples\n",
        "\n",
        "        train_acc_hist.append(train_acc)\n",
        "        test_acc_hist.append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch:2d} | train acc {train_acc:.3f} | test acc {test_acc:.3f}\")\n",
        "\n",
        "    return model, train_acc_hist, test_acc_hist\n"
      ],
      "metadata": {
        "id": "lIjlN1tbJzrU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single run for plotting\n",
        "print(\"Two Compartment Training\")\n",
        "tc_model, tc_train_acc, tc_test_acc = train_and_log(TCWrapper, num_epochs=10, seed=0)\n",
        "print()\n",
        "print(\"One Compartment Training\")\n",
        "sc_model, sc_train_acc, sc_test_acc = train_and_log(SCWrapper, num_epochs=10, seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3r2O7K5J1rg",
        "outputId": "c10a836c-6b0b-4951-ca6a-d41d4eb0b891"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two Compartment Training\n",
            "Epoch  0 | train acc 0.701 | test acc 1.000\n",
            "Epoch  1 | train acc 0.996 | test acc 1.000\n",
            "Epoch  2 | train acc 0.994 | test acc 1.000\n",
            "Epoch  3 | train acc 0.888 | test acc 0.883\n",
            "Epoch  4 | train acc 0.875 | test acc 0.872\n",
            "Epoch  5 | train acc 0.875 | test acc 0.860\n",
            "Epoch  6 | train acc 0.872 | test acc 0.879\n",
            "Epoch  7 | train acc 0.875 | test acc 0.868\n",
            "Epoch  8 | train acc 0.881 | test acc 0.884\n",
            "Epoch  9 | train acc 0.991 | test acc 1.000\n",
            "\n",
            "One Compartment Training\n",
            "Epoch  0 | train acc 0.501 | test acc 0.499\n",
            "Epoch  1 | train acc 0.498 | test acc 0.489\n",
            "Epoch  2 | train acc 0.490 | test acc 0.504\n",
            "Epoch  3 | train acc 0.737 | test acc 0.883\n",
            "Epoch  4 | train acc 0.880 | test acc 0.872\n",
            "Epoch  5 | train acc 0.875 | test acc 0.860\n",
            "Epoch  6 | train acc 0.873 | test acc 0.879\n",
            "Epoch  7 | train acc 0.875 | test acc 0.868\n",
            "Epoch  8 | train acc 0.881 | test acc 0.884\n",
            "Epoch  9 | train acc 0.873 | test acc 0.880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Testing Accuracy Over Epochs"
      ],
      "metadata": {
        "id": "LfF6QAq49OXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = range(len(tc_train_acc))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(epochs, tc_test_acc, label=\"Two-comp (test)\")\n",
        "plt.plot(epochs, sc_test_acc, label=\"One-comp (test)\", linestyle=\"--\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.5, 1.05)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.title(\"Temporal coincidence task: 1-comp vs 2-comp\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "4dLrNy2xKAda",
        "outputId": "506357a3-83eb-4ed8-c831-80af82b00dea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ablation experiment: basal vs apical input\n",
        "\n",
        "To test whether the two-compartment model really **uses both channels**, we run a simple ablation experiment on the trained model.\n",
        "\n",
        "Each input sequence has shape `[T, B, 2]`:\n",
        "\n",
        "- `x[..., 0]` = **basal** input channel  \n",
        "- `x[..., 1]` = **apical** input channel  \n",
        "\n",
        "We evaluate the model under three conditions:\n",
        "\n",
        "1. **Normal input**  \n",
        "   - Both basal and apical channels are intact.  \n",
        "   - This is the reference accuracy.\n",
        "\n",
        "2. **No apical**  \n",
        "   - We set `x[..., 1] = 0.0` for all time steps.  \n",
        "   - Basal input is still present, but the apical compartment receives no spikes.  \n",
        "   - If accuracy drops, it means apical input was contributing useful information.\n",
        "\n",
        "3. **No basal**  \n",
        "   - We set `x[..., 0] = 0.0` for all time steps.  \n",
        "   - Apical input is still present, but the basal compartment receives no spikes.  \n",
        "   - If accuracy drops more here, it suggests basal input is more critical for the decision.\n",
        "\n",
        "For each condition, we:\n",
        "\n",
        "- Run the model on the test set  \n",
        "- Compute test accuracy  \n",
        "\n",
        "By comparing:\n",
        "\n",
        "- **normal accuracy**\n",
        "- **accuracy with no apical**\n",
        "- **accuracy with no basal**\n",
        "\n",
        "we can see:\n",
        "\n",
        "- Whether the model is actually using **both** compartments  \n",
        "- Whether basal and apical play **different roles** (e.g., one is more important, or they fail in different ways), instead of just being redundant copies of the same signal.\n"
      ],
      "metadata": {
        "id": "tUA3n04Q-v3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_with_ablation(model, loader, ablate_apical=False, ablate_basal=False):\n",
        "    model.eval()\n",
        "    total_correct, total_examples = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.transpose(0,1).to(device)  # [T,B,2]\n",
        "            y = y.to(device)\n",
        "\n",
        "            if ablate_apical:\n",
        "                x = x.clone()\n",
        "                x[..., 1] = 0.0\n",
        "            if ablate_basal:\n",
        "                x = x.clone()\n",
        "                x[..., 0] = 0.0\n",
        "\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=-1)\n",
        "            total_correct += (preds == y).sum().item()\n",
        "            total_examples += y.size(0)\n",
        "\n",
        "    return total_correct / total_examples\n"
      ],
      "metadata": {
        "id": "Rrc1dHL3K9an"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rebuild a test_loader for evaluation\n",
        "test_dataset  = BasalApicalDataset(n_samples=2000, T=T, t_apical=t_apical,\n",
        "                                   delay=delay, device=device)\n",
        "test_loader   = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "tc_norm   = eval_with_ablation(tc_model, test_loader)\n",
        "tc_no_ap  = eval_with_ablation(tc_model, test_loader, ablate_apical=True)\n",
        "tc_no_bas = eval_with_ablation(tc_model, test_loader, ablate_basal=True)\n",
        "\n",
        "print(\"Two-comp: normal    \", tc_norm)\n",
        "print(\"Two-comp: no apical \", tc_no_ap)\n",
        "print(\"Two-comp: no basal  \", tc_no_bas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSljhDdCK_yh",
        "outputId": "a479bcb0-91ba-4692-d679-6658421de7fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two-comp: normal     1.0\n",
            "Two-comp: no apical  0.498\n",
            "Two-comp: no basal   0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the model relies on both compartments since the accuracy shoots down once one is ablated"
      ],
      "metadata": {
        "id": "BtUzfNsu-0KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion and takeaways\n",
        "\n",
        "### What was the task?\n",
        "\n",
        "In this notebook, we built a very simple **temporal coincidence detection** task:\n",
        "\n",
        "- Input is a sequence of length `T` with **two channels**:\n",
        "  - Channel 0 = apical input  \n",
        "  - Channel 1 = basal input\n",
        "- Class 1 (“coincidence”): apical spikes slightly *before* basal, with a fixed delay.\n",
        "- Class 0 (“non-coincidence”): basal spikes at the “expected” time, but apical is either absent or spikes at a clearly wrong time.\n",
        "\n",
        "So the question is:\n",
        "> *Did the apical spike correctly predict the basal spike in time?*\n",
        "\n",
        "This is exactly the kind of computation that **two-compartment neurons** are hypothesized to be good at in biology.\n",
        "\n",
        "---\n",
        "\n",
        "### What models did we compare?\n",
        "\n",
        "We trained two spiking networks using snnTorch and surrogate gradients:\n",
        "\n",
        "1. **Single-compartment SNN**\n",
        "   - Standard leaky integrate-and-fire (LIF) neurons.\n",
        "   - Both apical and basal inputs are just treated as a 2D input vector.\n",
        "\n",
        "2. **Two-compartment SNN**\n",
        "   - Each neuron has a **basal compartment** and an **apical compartment**.\n",
        "   - Basal and apical voltages evolve separately over time.\n",
        "   - The soma voltage is a weighted combination of the two, and spikes when it crosses threshold.\n",
        "\n",
        "In both cases, classification is done from the **spike counts over time**.\n",
        "\n",
        "---\n",
        "\n",
        "### Key results\n",
        "\n",
        "- Both architectures can learn the task with high accuracy.\n",
        "- In our runs:\n",
        "  - The **two-compartment SNN** consistently reached ~100% test accuracy across random seeds.\n",
        "  - The **single-compartment SNN** also performed well, but showed **slightly lower and more variable** accuracy across seeds.\n",
        "\n",
        "To probe whether the compartments really matter, I ran **ablations**:\n",
        "\n",
        "- **No apical input** (set apical channel to zero at test time):\n",
        "  - Accuracy dropped to about chance.\n",
        "  - This shows the model is genuinely using apical information to solve the task.\n",
        "\n",
        "- **No basal input**:\n",
        "  - Accuracy also dropped, but in a different pattern.\n",
        "  - The network relies on both basal and apical streams, not just one.\n",
        "\n",
        "---\n",
        "\n",
        "### What does this tell us?\n",
        "\n",
        "- On this simple timing-based task, a two-compartment neuron:\n",
        "  - Naturally captures the idea that **“apical predicts basal”** via temporal structure.\n",
        "  - Gives slightly more stable performance than a single-compartment neuron.\n",
        "\n",
        "- The **two streams (basal vs apical)** are not redundant:\n",
        "  - Removing apical input specifically breaks the ability to detect the predictive timing relationship.\n",
        "  - This mirrors the biological idea that apical dendrites can carry **“prediction” or “context”** signals that modulate feedforward input.\n",
        "\n",
        "---\n",
        "\n",
        "### Limitations and next steps\n",
        "\n",
        "- This is a **toy task** with extremely low-dimensional input and a very simple decision rule.\n",
        "- Everything is still trained with **global backpropagation**, not a purely local biological learning rule.\n",
        "- A natural next step (which we explored in a separate notebook) is:\n",
        "  - Trying **local learning rules** and self-prediction ideas.\n",
        "  - Scaling to more complex, higher-dimensional tasks.\n",
        "\n",
        "Even so, this toy setup is a clean, controlled example where **compartments and timing directly matter**, and where two-compartment neurons behave differently from “just another” single-compartment model.\n"
      ],
      "metadata": {
        "id": "m6BBM8ajQj1_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDIrUdcbSqGa"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}